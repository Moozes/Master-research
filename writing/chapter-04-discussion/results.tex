\section{Introduction}
in this chapter we are going to compare the various descussed methods  depending on multiple criterias and different point of views, in other terms the comparaison will be based on the different datasets used, the different methods and there performance, interpritability and applicability in real life scenarious

\section{datasets}
    These are the famous dataset used and some of the problems encountered using them:\\ 
    \begin{itemize}
    \item \textbf{ISIC 2019}
    \item \textbf{Kaggle}
    \item \textbf{PH2}
    \item \textbf{Hallym}, \emph{problem} performance depends on ethnicity
    \item \textbf{Dermquest}, \emph{problem} unsatisfactory for non-melanoma
    \item \textbf{DermIS}, \emph{problem} unsatisfactory for non-melanoma
    \item \textbf{HAM10000 ISIC 2018}, \emph{problem} biased for diverse dataset (but works good for binary classification)
    \item \textbf{Dermnet}, \emph{problem} able to identify only few skin lesions
    \item \textbf{ISBI}
    \item \textbf{Atlas Contents}
    \item Compile your own dataset if you have a new idea (such as: Raman spectra, clinical data+image)
    \item A general problem met with all datasets is the preprocessing and cleaning (such as smoothing and haire removal)
\end{itemize}


\section{Extracted Features}
    After talking about these datasets, we are going to talk about the features extracted from them, which are GLCM, ABCD, LBP, Autocorrelation, correlation, Standard vector and other statistical features (such has arithmetic mean, standard deviation for Raman spectra) all of these features are proven to play an important role in the classification process but depending on your situation and the dataset you use you could find for example a single feature that presents the same performance as the group of features (like in the case of ~\cite{Daniella2021} where they used the derivative only) and you can simply check that by trainning the model with different combination of features untill you find an important difference or by using statistical methods that tells you the degree of discrimination of each feature.

\section{Methods}
    these are the used algorithms:
    \begin{itemize}
        \item SVM 
        \item hybrid adaboost SVM (Adaboost: adaptive boosting, it can be used with various algorithms to increase the performance)
        \item MSVM (multi-class) 
        \item lightGBM (complex decision tree open source software) 
        \item ANN
        \item DNN (deep neural networks) with Dragonfly optimization algorithm 
        \item CNN and its famous architectures 
        \begin{itemize}
            \item DCNN (deep CNN) 
            \item u-net for medical image segmentation
            \item Resnet 
            \item FCRN (Fully Convolutional Residual Networks) 
            \item CNN + Whale algorithm aplied for optimization
            \item GoogleNet 
            \item DenseNet 
            \item MobileNet 
            \item Inception v3
            \item DLS (deep learning studio) 
        \end{itemize}
    \end{itemize}
    An overall view of letirature tells us that the performance metric of both deep learning and machine learning is the same with deep learning being slightly better. the best of both sides are: (MSVM reaching an accuracy of 96.25\% and lightGBM acheiving an AUC $>$97\%) and (ANN performance metric, accuracy, specificity... all being above 97\% and inceptionv3 CNN architecture reaching and AUC of 99\%) 


    
\section{Applicability}
    when we talk about applicability we need to consider 4 things (place, dataset, method, interpretability)
    
    \textbf{I-} where do plan on using your algorithm: in a local clinic or a national hospital or internationnaly ?
    
    \textbf{II-} is the dataset used compatible with place off applicability, in other words if you plan on applying your method locally your trainning set need to be local also, and not from another country (so famous international datasets wont be sufficant) or if you plan on using your method in a national/international level your dataset need to be comprehensive and balanced in all ways: skin color tones, ethnicity, age, sex...etc 
    
    \textbf{III-} thirdly your method need to take into consideration the available dataset and the place of applicability, do you want milticlass classification or binary classification ?, is the place you planing on applying you method in capable of aquiring the needed technology ? (like in the case of Raman Spectroscopy, not all clinics are capable of having such a technology), is your method of diagnosis compatible with cultural specifications (invasive or non-invasive)? 

    \textbf{IV-} lastly, is your method interpretabe? because most the mentioned algorithms above are not naturally interpretabe (black boxes), so unless they get interpreted they cant be trusted in high stakes scenarios.